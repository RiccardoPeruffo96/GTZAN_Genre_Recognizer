{"cells":[{"cell_type":"markdown","source":["# Lab Exercise: Comparing Clustering Algorithms on the Digits Dataset\n","\n","### Objective:\n","In this lab, you will compare different clustering algorithms—K-Means, DBSCAN, and Hierarchical Clustering—on the **Digits** dataset. You will evaluate the performance of these algorithms using clustering evaluation metrics such as **Silhouette Score**, **Dunn Index**, and **Davies-Bouldin Index**.\n","\n","### Tasks:\n","\n","1. **Data Preprocessing**:\n","   - Load the **Digits** dataset from `sklearn.datasets`.\n","   - Preprocess the data as needed (scaling, reshaping, etc.).\n","\n","2. **Clustering**:\n","   - Apply the following clustering algorithms:\n","     - **K-Means**\n","     - **DBSCAN**\n","     - **Hierarchical Clustering**\n","\n","3. **Evaluation**:\n","   - For each algorithm, compute the clustering evaluation metrics:\n","     - **Silhouette Score**\n","     - **Dunn Index**\n","     - **Davies-Bouldin Index**\n","\n","4. **Comparison**:\n","   - Compare the clustering results and discuss which algorithm performs best on the Digits dataset based on the evaluation metrics.\n","\n","# Discussions\n","\n","1. **Which algorithm performed best based on the silhouette score, Davies-Bouldin score, and Dunn index?**\n","\n","2. **How did the DBSCAN algorithm perform, given its sensitivity to parameters like eps and min_samples?**\n","\n","3. **How does K-Means compare with Hierarchical Clustering, especially in terms of cluster structure?**\n"],"metadata":{"id":"6Uv-T-FDY92o"}},{"cell_type":"code","source":["### Solution:\n","# Step 1: Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans, DBSCAN\n","from sklearn.metrics import silhouette_score, davies_bouldin_score\n","from scipy.spatial.distance import cdist\n","from sklearn.cluster import AgglomerativeClustering"],"metadata":{"id":"_ZYk1dwiZP30","executionInfo":{"status":"ok","timestamp":1732472489675,"user_tz":-60,"elapsed":6700,"user":{"displayName":"Cigdem Beyan","userId":"00242028384913531025"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Step 2: Load and preprocess the Digits dataset\n","digits = load_digits()\n","X = digits.data\n","y = digits.target\n","\n","# Standardize the data (important for clustering algorithms)\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"gBhRskY4ZUd3","executionInfo":{"status":"ok","timestamp":1732472493178,"user_tz":-60,"elapsed":368,"user":{"displayName":"Cigdem Beyan","userId":"00242028384913531025"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Step 3: Apply K-Means Clustering\n","kmeans = KMeans(n_clusters=10, random_state=42)\n","kmeans_labels = kmeans.fit_predict(X_scaled)\n","\n","# Step 4: Apply DBSCAN Clustering\n","dbscan = DBSCAN(eps=5, min_samples=10)\n","dbscan_labels = dbscan.fit_predict(X_scaled)\n","\n","# Step 5: Apply Hierarchical Clustering\n","hierarchical = AgglomerativeClustering(n_clusters=10)\n","hierarchical_labels = hierarchical.fit_predict(X_scaled)"],"metadata":{"id":"1WfFy4bJZXLh","executionInfo":{"status":"ok","timestamp":1732472499740,"user_tz":-60,"elapsed":2033,"user":{"displayName":"Cigdem Beyan","userId":"00242028384913531025"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Step 6: Compute Clustering Evaluation Metrics\n","\n","# Function to compute Dunn Index\n","def dunn_index(X, labels):\n","    distances = cdist(X, X, metric='euclidean')\n","    inter_cluster_distances = []\n","    intra_cluster_distances = []\n","    for label in np.unique(labels):\n","        cluster_points = X[labels == label]\n","        intra_cluster_distances.append(np.mean(cdist(cluster_points, cluster_points, metric='euclidean')))\n","        for other_label in np.unique(labels):\n","            if label != other_label:\n","                other_cluster_points = X[labels == other_label]\n","                inter_cluster_distances.append(np.min(cdist(cluster_points, other_cluster_points, metric='euclidean')))\n","    dunn = np.min(inter_cluster_distances) / np.max(intra_cluster_distances)\n","    return dunn\n","\n","# Compute the metrics\n","silhouette_kmeans = silhouette_score(X_scaled, kmeans_labels)\n","davies_bouldin_kmeans = davies_bouldin_score(X_scaled, kmeans_labels)\n","dunn_kmeans = dunn_index(X_scaled, kmeans_labels)\n","\n","silhouette_dbscan = silhouette_score(X_scaled, dbscan_labels) if len(set(dbscan_labels)) > 1 else -1\n","davies_bouldin_dbscan = davies_bouldin_score(X_scaled, dbscan_labels) if len(set(dbscan_labels)) > 1 else -1\n","dunn_dbscan = dunn_index(X_scaled, dbscan_labels) if len(set(dbscan_labels)) > 1 else -1\n","\n","silhouette_hierarchical = silhouette_score(X_scaled, hierarchical_labels)\n","davies_bouldin_hierarchical = davies_bouldin_score(X_scaled, hierarchical_labels)\n","dunn_hierarchical = dunn_index(X_scaled, hierarchical_labels)"],"metadata":{"id":"QBvJfBrmZbD1","executionInfo":{"status":"ok","timestamp":1732472509518,"user_tz":-60,"elapsed":2200,"user":{"displayName":"Cigdem Beyan","userId":"00242028384913531025"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 7: Display the Results\n","print(\"K-Means:\")\n","print(f\"Silhouette Score: {silhouette_kmeans}\")\n","print(f\"Davies-Bouldin Score: {davies_bouldin_kmeans}\")\n","print(f\"Dunn Index: {dunn_kmeans}\")\n","\n","print(\"\\nDBSCAN:\")\n","print(f\"Silhouette Score: {silhouette_dbscan}\")\n","print(f\"Davies-Bouldin Score: {davies_bouldin_dbscan}\")\n","print(f\"Dunn Index: {dunn_dbscan}\")\n","\n","print(\"\\nHierarchical Clustering:\")\n","print(f\"Silhouette Score: {silhouette_hierarchical}\")\n","print(f\"Davies-Bouldin Score: {davies_bouldin_hierarchical}\")\n","print(f\"Dunn Index: {dunn_hierarchical}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AO4QrcxMZft-","executionInfo":{"status":"ok","timestamp":1732472819911,"user_tz":-60,"elapsed":351,"user":{"displayName":"Cigdem Beyan","userId":"00242028384913531025"}},"outputId":"1bf0a617-2688-41fa-8ccc-03029273a7a9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["K-Means:\n","Silhouette Score: 0.13558208876901615\n","Davies-Bouldin Score: 1.8060790632374897\n","Dunn Index: 0.15696004443168518\n","\n","DBSCAN:\n","Silhouette Score: -0.029162417635556125\n","Davies-Bouldin Score: 3.4498585825016015\n","Dunn Index: 0.18592980647707277\n","\n","Hierarchical Clustering:\n","Silhouette Score: 0.12532527779196986\n","Davies-Bouldin Score: 1.9671781554189507\n","Dunn Index: 0.10830374388193056\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}